[tool:pytest]
# Main pytest configuration file for torch-inference framework

# Test discovery
testpaths = tests
python_files = test_*.py *_test.py
python_classes = Test* *Tests
python_functions = test_*

# Minimum version requirement
minversion = 7.0

# Add project root to Python path
pythonpath = . framework

# Default command line options - optimized for speed and stability
addopts = 
    --strict-markers
    --strict-config
    --durations=15
    --color=yes
    --maxfail=5
    --log-file-level=ERROR
    --capture=sys
    --log-cli-level=WARNING
    --timeout=60
    --timeout-method=thread
    -v
    --tb=short

# Asyncio configuration - more restrictive
asyncio_mode = strict
asyncio_default_fixture_loop_scope = function

# Markers for test categorization
markers =
    asyncio: Asynchronous tests
    unit: Unit tests (fast, isolated)
    integration: Integration tests (slower, end-to-end)
    slow: Slow running tests (>5 seconds)
    gpu: Tests requiring GPU/CUDA
    tensorrt: Tests requiring TensorRT
    onnx: Tests requiring ONNX runtime
    enterprise: Enterprise feature tests
    benchmark: Performance benchmark tests
    smoke: Smoke tests for quick validation
    regression: Regression tests
    security: Security-related tests
    api: API endpoint tests
    model: Tests requiring real models
    mock: Tests using only mock objects
    audio: Audio processing tests
    autoscaling: Autoscaling functionality tests
    zero_scaler: Zero scaling tests
    model_loader: Dynamic model loader tests
    metrics: Metrics collection tests
    performance: Performance and stress tests
    load_balancing: Load balancing tests
    health_monitoring: Health monitoring tests

# Test timeout (in seconds) - individual test limit - reduced for Windows compatibility
timeout = 30
timeout_method = thread

# Global test suite timeout - entire test run limited to 15 minutes (900 seconds)
# This prevents the entire test suite from running longer than 15 minutes
# Note: pytest-timeout doesn't support session-level timeouts directly.
# For CI/CD, use external timeout mechanisms like:
# - Windows: timeout /t 900 uv run pytest
# - Unix: timeout 900s uv run pytest
# - GitHub Actions: timeout-minutes: 15
session_timeout = 900

# Warnings control - ignore all warnings by default + memory cleanup
filterwarnings =
    ignore
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning
    ignore::FutureWarning
    ignore::RuntimeWarning
    ignore::ImportWarning
    ignore::ResourceWarning
    ignore::BytesWarning
    ignore:Model registry not found:UserWarning
    ignore:coroutine.*was never awaited:RuntimeWarning
    ignore:.*unclosed.*:ResourceWarning
    ignore:.*deprecated.*:DeprecationWarning
    ignore:.*FutureWarning.*
    ignore:.*UserWarning.*
    error::ResourceWarning:__main__
    
# Memory optimization settings
python_flags = -W ignore

# Logging configuration - optimized for speed
log_cli = false
log_cli_level = WARNING
log_cli_format = %(levelname)s: %(message)s
log_cli_date_format = %H:%M:%S

# File logging configuration - minimal for speed
log_file = test.log
log_file_level = ERROR
log_file_format = %(asctime)s [%(levelname)s] %(message)s
log_file_date_format = %H:%M:%S

# Coverage settings (when using pytest-cov)
# These are defaults, can be overridden via command line
addopts_coverage = 
    --cov=framework
    --cov-report=html:htmlcov
    --cov-report=xml:coverage.xml
    --cov-report=term-missing:skip-covered
    --cov-report=lcov:coverage.lcov
    --cov-fail-under=80
    --cov-branch

# Distributed testing options (when using pytest-xdist)
addopts_parallel = 
    -n auto
    --dist worksteal

# JUnit XML output for CI/CD
junit_family = xunit2
junit_suite_name = torch_inference_tests
junit_duration_report = call
junit_log_passing_tests = true

# Cache configuration - enable for faster reruns
cache_dir = .pytest_cache

# Performance optimization settings
# Use faster collection strategy
collect_ignore = setup.py

# Optimize imports
import_mode = importlib

# Force garbage collection after each test
addopts_gc = --forked

# Console output options - optimized for speed
console_output_style = count

# Live logging
log_auto_indent = true

# Doctest options
doctest_optionflags = NORMALIZE_WHITESPACE IGNORE_EXCEPTION_DETAIL ELLIPSIS

# Required plugins (these will be auto-loaded if available)
required_plugins =
    pytest-asyncio >= 0.21.0

# Optional plugins (will be used if installed)
# pytest-cov: Coverage reporting
# pytest-xdist: Parallel test execution  
# pytest-benchmark: Performance benchmarking
# pytest-mock: Enhanced mocking capabilities
# pytest-timeout: Test timeouts
# pytest-html: HTML reports

# Additional error reporting options - optimized for speed
# Capture output efficiently
log_capture = true
log_level = ERROR

# Capture stdout/stderr efficiently
capture = sys

# Show concise tracebacks for faster reading
tb_style = short

# =============================================================================
# SPEED OPTIMIZATION PROFILES
# =============================================================================
# You can override the default addopts by setting PYTEST_ADDOPTS environment variable
# or using command line options for different scenarios:

# DEVELOPMENT (fastest - unit tests only):
# pytest tests/unit -m "not slow" --tb=line --disable-warnings -x

# FAST INTEGRATION (medium speed):
# pytest tests/integration -m "not slow" --tb=short --maxfail=3

# FULL SUITE WITH COVERAGE (slower but complete):
# pytest --cov=framework --cov-report=html --tb=short

# DEBUG MODE (slowest but most verbose):
# pytest -v -s --tb=long --log-cli-level=DEBUG --capture=no

# CI/CD OPTIMIZED:
# pytest -n auto --dist=loadfile --tb=short --junitxml=test-results.xml

# QUICK SMOKE TEST:
# pytest -m "smoke" --tb=line -x

# PERFORMANCE BENCHMARKS ONLY:
# pytest -m "benchmark" --benchmark-only
