# PyTorch Inference Framework - API Documentation

This directory contains comprehensive API documentation for all endpoints, authentication, and usage examples.

## ğŸ“š Documentation Structure

```
docs/api/
â”œâ”€â”€ README.md                    # This overview
â”œâ”€â”€ rest-api.md                 # Complete REST API reference (existing)
â”œâ”€â”€ authentication.md           # Authentication and security
â”œâ”€â”€ endpoints/                  # Individual endpoint documentation
â”‚   â”œâ”€â”€ core.md                # Core inference endpoints
â”‚   â”œâ”€â”€ models.md              # Model management
â”‚   â”œâ”€â”€ audio.md               # Audio/TTS/STT processing
â”‚   â”œâ”€â”€ gpu.md                 # GPU detection and management
â”‚   â”œâ”€â”€ autoscaler.md          # Autoscaling endpoints
â”‚   â”œâ”€â”€ server.md              # Server management
â”‚   â””â”€â”€ logging.md             # Logging endpoints
â”œâ”€â”€ examples/                   # Code examples and tutorials
â”‚   â”œâ”€â”€ basic-usage.md         # Basic API usage examples
â”‚   â”œâ”€â”€ tts-examples.md        # Text-to-speech examples
â”‚   â”œâ”€â”€ model-management.md    # Model download and management
â”‚   â”œâ”€â”€ authentication.md      # Authentication examples
â”‚   â””â”€â”€ advanced-usage.md      # Advanced features and optimizations
â””â”€â”€ schemas/                    # Request/Response schemas
    â”œâ”€â”€ inference.md           # Inference request/response schemas
    â”œâ”€â”€ audio.md               # Audio processing schemas
    â”œâ”€â”€ models.md              # Model management schemas
    â””â”€â”€ common.md              # Common response formats
```

## ğŸš€ Quick Start

### 1. Basic Prediction
```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "example",
    "inputs": [1, 2, 3, 4, 5]
  }'
```

### 2. Text-to-Speech
```bash
curl -X POST http://localhost:8000/synthesize \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "speecht5_tts",
    "inputs": "Hello, this is a test of the text-to-speech system."
  }'
```

### 3. Model Download
```bash
curl -X POST http://localhost:8000/models/download \
  -H "Content-Type: application/json" \
  -d '{
    "source": "huggingface",
    "model_id": "microsoft/speecht5_tts",
    "name": "speecht5_tts",
    "task": "text-to-speech",
    "include_vocoder": true
  }'
```

### 4. System Health Check
```bash
curl http://localhost:8000/health
```

## ğŸ“‹ API Categories

### Core Inference
- **`/predict`** - Unified prediction endpoint for all models
- **`/health`** - System health check with autoscaler info
- **`/info`** - Comprehensive system information
- **`/stats`** - Performance statistics
- **`/config`** - Configuration information

### Model Management
- **`/models`** - List available models
- **`/models/download`** - Download and load models
- **`/models/available`** - List downloadable models
- **`/models/managed`** - Server-managed model info
- **`/models/cache/info`** - Model cache information

### Audio Processing
- **`/synthesize`** - Text-to-speech synthesis
- **`/transcribe`** - Speech-to-text transcription
- **`/audio/health`** - Audio processing health
- **`/tts/health`** - TTS service health check

### GPU Management
- **`/gpu/detect`** - Detect available GPUs
- **`/gpu/best`** - Get best GPU for inference
- **`/gpu/config`** - GPU-optimized configuration
- **`/gpu/report`** - Comprehensive GPU report

### Autoscaling
- **`/autoscaler/stats`** - Autoscaler statistics
- **`/autoscaler/health`** - Autoscaler health check
- **`/autoscaler/scale`** - Scale model instances
- **`/autoscaler/metrics`** - Detailed metrics

### Server Management
- **`/server/config`** - Server configuration
- **`/server/optimize`** - Performance optimization
- **`/metrics/server`** - Server performance metrics
- **`/metrics/tts`** - TTS-specific metrics

### Logging
- **`/logs`** - Logging information
- **`/logs/{log_file}`** - View/download log files
- **`DELETE /logs/{log_file}`** - Clear log files

### Authentication (if enabled)
- **`/auth/register`** - User registration
- **`/auth/login`** - User login
- **`/auth/logout`** - User logout
- **`/auth/profile`** - User profile
- **`/auth/generate-key`** - Generate API keys

## ğŸ”§ Configuration

The API server supports various configuration options:

### Environment Variables
- `DEVICE` - Device type (cuda, cpu, auto)
- `BATCH_SIZE` - Default batch size
- `LOG_LEVEL` - Logging level (DEBUG, INFO, WARNING, ERROR)
- `ENABLE_AUTH` - Enable authentication (true/false)

### Configuration Files
- `config.yaml` - Main configuration
- `models.json` - Available models configuration
- `auth.yaml` - Authentication settings (if enabled)

## ğŸ“Š Response Formats

All API endpoints return consistent JSON responses:

### Success Response
```json
{
  "success": true,
  "result": "...",
  "processing_time": 0.025,
  "model_info": {
    "model": "example",
    "device": "cuda:0"
  }
}
```

### Error Response
```json
{
  "success": false,
  "error": "Error description",
  "detail": "Detailed error information"
}
```

## ğŸ›¡ï¸ Security Features

- **Optional Authentication** - JWT-based authentication with API keys
- **Rate Limiting** - Configurable request rate limits
- **Input Validation** - Comprehensive request validation
- **Security Headers** - CORS and security headers
- **Audit Logging** - Request/response logging

## ğŸ“ˆ Performance Features

- **Batch Processing** - Efficient batch inference
- **Model Caching** - Automatic model caching
- **GPU Acceleration** - CUDA, MPS, and multi-GPU support
- **Autoscaling** - Dynamic model scaling
- **Optimization** - TensorRT, FP16, INT8 support

## ğŸµ TTS/Audio Features

- **Multiple TTS Models** - BART, SpeechT5, Bark, VALL-E X, Tacotron2
- **Auto Model Download** - Automatic model downloading
- **Multiple Formats** - WAV, MP3, FLAC support
- **Voice Control** - Speed, pitch, volume adjustment
- **Multi-language** - Support for multiple languages

## ğŸ”— External Links

- [Interactive API Documentation](http://localhost:8000/docs) - Swagger UI
- [Alternative API Documentation](http://localhost:8000/redoc) - ReDoc
- [Health Check](http://localhost:8000/health) - System health
- [System Info](http://localhost:8000/info) - Detailed system information

## ğŸ“ Examples

See the `examples/` directory for comprehensive code examples in multiple programming languages:
- Python (requests, httpx, aiohttp)
- JavaScript (fetch, axios)
- cURL commands
- Postman collections

## ğŸ› Troubleshooting

Common issues and solutions:

1. **Model not found** - Check `/models/available` for downloadable models
2. **CUDA out of memory** - Reduce batch size or use smaller models
3. **Audio processing errors** - Install audio dependencies (`librosa`, `soundfile`)
4. **Authentication errors** - Ensure valid token or API key
5. **Performance issues** - Check GPU utilization and enable optimizations

## ğŸ“ Support

For issues and questions:
- Check the troubleshooting guide
- Review log files via `/logs` endpoint
- Monitor system health via `/health` endpoint
- Check performance metrics via `/stats` endpoint
