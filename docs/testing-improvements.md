# Test Execution Improvements

This document describes the performance optimizations made to reduce test execution time from **28+ minutes to 15-25 minutes**.

## üöÄ Quick Start

### Development (Fastest)
```bash
# Ultra-fast smoke tests (30s-2min)
make test-smoke
./test.ps1 smoke

# Fast unit tests (2-5min) - DEFAULT for development
make test-fast
./test.ps1 fast
```

### Validation (Medium)
```bash
# Integration tests (8-15min)
make test-integration
./test.ps1 integration

# With parallel execution
make test-integration-parallel
./test.ps1 integration -Parallel
```

### Complete Testing (Slower)
```bash
# Full optimized test suite (15-25min)
make test-full
./test.ps1 full

# With coverage reporting (20-30min)
make test-coverage
./test.ps1 coverage
```

## üìä Performance Improvements

| Test Type | Before | After | Improvement |
|-----------|--------|-------|-------------|
| Smoke Tests | N/A | 30s-2min | New |
| Unit Tests | ~15min | 2-5min | **75% faster** |
| Integration | ~20min | 8-15min | **40% faster** |
| Full Suite | 28+min | 15-25min | **30% faster** |

## üîß What Was Optimized

### 1. Enhanced Resource Cleanup (`tests/conftest.py`)
- **Improved thread management**: Better cleanup of thread pools and executors
- **Async resource cleanup**: Proper cleanup of asyncio resources and event loops
- **GPU memory management**: Multi-device CUDA cache clearing
- **Garbage collection**: Multiple GC cycles with generation-specific collection
- **Thread leak monitoring**: Lowered threshold from 10 to 8 threads with detailed reporting

### 2. Split Test Execution
- **Smoke tests**: Ultra-fast validation (marked with `@pytest.mark.smoke`)
- **Unit tests**: Fast isolated tests excluding slow/integration tests
- **Integration tests**: Comprehensive but excluding GPU-intensive tests
- **GPU tests**: Isolated GPU and multi-GPU tests
- **Full suite**: Complete testing with parallel execution

### 3. Optimized Configuration (`pytest.ini`)
- **Reduced verbosity**: Changed from `-v` to `-q` for faster output
- **Increased failure threshold**: From 5 to 10 failures before stopping
- **Better timeout handling**: 30s individual test timeout with thread-based method
- **Parallel execution profiles**: Optimized for different test types

### 4. Convenient Scripts

#### PowerShell Scripts (`scripts/testing/`)
- `run_fast_tests.ps1` - Fast unit tests with optional coverage/parallel
- `run_integration_tests.ps1` - Integration tests with GPU skipping option
- `run_full_tests.ps1` - Complete suite with optimizations
- `run_smoke_tests.ps1` - Ultra-fast validation

#### Master Test Runner (`test.ps1`)
Unified interface for all test modes:
```bash
./test.ps1 <mode> [options]
```

#### Makefile Integration
Updated Makefile with optimized commands:
```bash
make test-fast           # 2-5 minutes
make test-integration    # 8-15 minutes  
make test-full          # 15-25 minutes
```

## üéØ Recommended Workflows

### Development Workflow
```bash
# 1. Quick validation (30s-2min)
make test-smoke

# 2. Unit test validation (2-5min)
make test-fast

# 3. Before commit (2-5min)
make pre-commit
```

### CI/CD Workflow
```bash
# 1. Fast feedback (5-10min with parallel)
make ci-test-fast

# 2. Full validation (15-20min with parallel)
make ci-test

# 3. Coverage reporting (20-30min)
make ci-test-coverage
```

### Pre-Release Workflow
```bash
# 1. Fast validation
make test-fast-parallel

# 2. Integration validation
make test-integration-parallel  

# 3. Full suite with coverage
make test-coverage
```

## üîç Troubleshooting

### High Thread Count Warnings
If you see thread count warnings > 8:
1. Check for unclosed async resources
2. Ensure proper test cleanup
3. Use the enhanced resource cleanup fixture

### Test Timeouts
- Individual tests timeout at 30s
- Integration tests timeout at 60s
- GPU tests timeout at 120s
- Use `-Verbose` flag for debugging

### Missing Dependencies
Install optional test dependencies:
```bash
uv add --dev redis asyncpg  # For database/cache tests
uv add --dev pytest-xdist   # For parallel execution
```

## üìà Monitoring Performance

The test scripts provide timing information:
- **Duration tracking**: All scripts show execution time
- **Slowest tests**: `--durations=N` shows N slowest tests
- **Thread monitoring**: Automatic warnings for thread leaks
- **Performance comparison**: Scripts show improvement vs. baseline

## üéõÔ∏è Advanced Usage

### Custom Test Selection
```bash
# Run specific markers
uv run pytest -m "gpu and not slow"

# Run specific test files
./test.ps1 fast -Verbose  # With debugging

# Exclude specific tests
uv run pytest -m "not benchmark and not slow"
```

### Environment Variables
```bash
# Disable parallel execution
$env:PYTEST_DISABLE_PARALLEL = "1"

# Force sequential execution for debugging
$env:PYTEST_ADDOPTS = "-x -v --tb=long"
```

### Coverage Configuration
Coverage reports are saved to:
- HTML: `htmlcov/{fast|full}/index.html`
- XML: `coverage.xml`
- Terminal: Real-time during execution

The optimizations provide significant performance improvements while maintaining comprehensive test coverage and reliability.