name: Tests

on:
  push:
    branches: [ main, dev ]
  pull_request:
    branches: [ main, dev ]
  workflow_dispatch:  # Allow manual triggering

jobs:
  validate:
    runs-on: ubuntu-latest
    outputs:
      should_run: ${{ steps.changes.outputs.should_run }}
    steps:
    - uses: actions/checkout@v4
    
    - name: Check if we should run tests
      id: changes
      run: |
        echo "should_run=true" >> $GITHUB_OUTPUT
        echo "Workflow validation passed"
    
    - name: Validate pyproject.toml
      run: |
        python -c "import tomllib; tomllib.load(open('pyproject.toml', 'rb'))" || \
        python -c "import tomli; tomli.load(open('pyproject.toml', 'rb'))" || \
        echo "Could not validate pyproject.toml, but continuing anyway"

  test:
    needs: validate
    if: needs.validate.outputs.should_run == 'true'
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.10", "3.11", "3.12"]
        include:
          # Test with GPU on Ubuntu
          - os: ubuntu-latest
            python-version: "3.10"
            gpu: true
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Install uv
      uses: astral-sh/setup-uv@v3
      with:
        version: "latest"
    
    - name: Set up Python ${{ matrix.python-version }}
      run: uv python install ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        uv sync --extra dev
    
    - name: Download test models
      run: |
        uv run python tests/models/create_test_models.py
      continue-on-error: true
    
    - name: Lint with ruff
      run: |
        uv run ruff check .
    
    - name: Check formatting with black
      run: |
        uv run black --check .
    
    - name: Check import sorting with isort
      run: |
        uv run isort --check-only .
    
    - name: Type check with mypy
      run: |
        uv run mypy framework
      continue-on-error: true
    
    - name: Run unit tests
      run: |
        uv run pytest tests/unit/ --cov=framework --cov-report=xml --junitxml=junit.xml -v
    
    - name: Run integration tests
      run: |
        uv run pytest tests/integration/ --cov=framework --cov-append --cov-report=xml --junitxml=junit-integration.xml -v
    
    - name: Run GPU tests
      if: matrix.gpu == true
      run: |
        # Only run if CUDA is available
        uv run python -c "import torch; exit(0 if torch.cuda.is_available() else 1)" && \
        uv run pytest -m gpu tests/ --cov=framework --cov-append --cov-report=xml -v || \
        echo "CUDA not available, skipping GPU tests"
    
    - name: Security scan with bandit
      run: |
        uv run bandit -r framework -f json -o bandit-report.json
        uv run bandit -r framework
      continue-on-error: true
    
    - name: Safety check
      run: |
        uv run safety check --json --output safety-report.json
        uv run safety check
      continue-on-error: true
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  benchmark:
    needs: validate
    if: needs.validate.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Install uv
      uses: astral-sh/setup-uv@v3
      with:
        version: "latest"
    
    - name: Set up Python
      run: uv python install 3.10
    
    - name: Install dependencies
      run: |
        uv sync --extra dev
    
    - name: Download test models
      run: |
        uv run python tests/models/create_test_models.py
      continue-on-error: true
    
    - name: Run benchmarks
      run: |
        uv run pytest -m benchmark --benchmark-only --benchmark-json=benchmark.json tests/
      continue-on-error: true
    
    - name: Store benchmark results
      uses: benchmark-action/github-action-benchmark@v1
      if: github.ref == 'refs/heads/main' && hashFiles('benchmark.json') != ''
      with:
        tool: 'pytest'
        output-file-path: benchmark.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true
      continue-on-error: true

  docs:
    needs: validate
    if: needs.validate.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Install uv
      uses: astral-sh/setup-uv@v3
      with:
        version: "latest"
    
    - name: Set up Python
      run: uv python install 3.10
    
    - name: Install dependencies
      run: |
        uv sync --extra docs
    
    - name: Check if mkdocs.yml exists
      run: |
        if [ -f "mkdocs.yml" ] || [ -f "mkdocs.yaml" ]; then
          echo "MkDocs configuration found"
          uv run mkdocs build --strict
        else
          echo "No MkDocs configuration found, skipping docs build"
        fi
    
    - name: Deploy docs to GitHub Pages
      if: github.ref == 'refs/heads/main' && (hashFiles('mkdocs.yml') != '' || hashFiles('mkdocs.yaml') != '')
      run: |
        uv run mkdocs gh-deploy --force

  docker:
    needs: validate
    if: needs.validate.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        load: true
        tags: torch-inference:test
    
    - name: Test in Docker
      run: |
        docker run --rm torch-inference:test python -m pytest tests/unit/ -v

  release:
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    needs: [validate, test, benchmark, docs, docker]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Install uv
      uses: astral-sh/setup-uv@v3
      with:
        version: "latest"
    
    - name: Set up Python
      run: uv python install 3.10
    
    - name: Install dependencies
      run: |
        uv sync --extra dev
        uv add twine
    
    - name: Build package
      run: |
        uv build
    
    - name: Check package
      run: |
        uv run twine check dist/*
    
    - name: Upload to Test PyPI
      if: success() && secrets.TEST_PYPI_API_TOKEN != ''
      uses: pypa/gh-action-pypi-publish@release/v1
      with:
        password: ${{ secrets.TEST_PYPI_API_TOKEN }}
        repository_url: https://test.pypi.org/legacy/
        skip_existing: true
